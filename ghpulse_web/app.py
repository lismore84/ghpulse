#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GHPulse æ•°æ®æŸ¥è¯¢Webåº”ç”¨
"""

from flask import Flask, jsonify, request, render_template
import pymysql
from pymysql import cursors
import os
from dotenv import load_dotenv
from datetime import datetime
import logging
import traceback

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGæ¨¡å¼æŸ¥çœ‹è¯¦ç»†é”™è¯¯
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 3306)),
    'user': os.getenv('WEB_DB_USER', 'web_user'),
    'password': os.getenv('WEB_DB_PASSWORD', ''),
    'database': os.getenv('DB_NAME', 'ghpulse'),
    'charset': 'utf8mb4',
    'cursorclass': cursors.DictCursor,
    'connect_timeout': 10
}

# æ˜¾ç¤ºé…ç½®ï¼ˆéšè—å¯†ç ï¼‰
logger.info("=" * 60)
logger.info("æ•°æ®åº“é…ç½®:")
logger.info(f"  Host: {DB_CONFIG['host']}")
logger.info(f"  Port: {DB_CONFIG['port']}")
logger.info(f"  User: {DB_CONFIG['user']}")
logger.info(f"  Database: {DB_CONFIG['database']}")
logger.info("=" * 60)


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        conn = pymysql.connect(**DB_CONFIG)
        logger.debug("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        return conn
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise


# ==================== å‰ç«¯è·¯ç”± ====================

@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    try:
        logger.info("è®¿é—®ä¸»é¡µ")
        return render_template('index.html')
    except Exception as e:
        logger.error(f"æ¸²æŸ“ä¸»é¡µå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return f"<h1>é”™è¯¯</h1><pre>{str(e)}\n\n{traceback.format_exc()}</pre>", 500


# ==================== APIè·¯ç”± ====================

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        cursor.close()
        conn.close()
        return jsonify({
            'status': 'ok', 
            'message': 'æ•°æ®åº“è¿æ¥æ­£å¸¸',
            'config': {
                'host': DB_CONFIG['host'],
                'port': DB_CONFIG['port'],
                'database': DB_CONFIG['database']
            }
        })
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return jsonify({
            'status': 'error', 
            'message': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/api/tables', methods=['GET'])
def get_tables():
    """è·å–æ‰€æœ‰è¡¨åŠå…¶ç»Ÿè®¡ä¿¡æ¯"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                TABLE_NAME as name,
                TABLE_COMMENT as comment,
                TABLE_ROWS as row_count,
                ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) as size_mb,
                ENGINE as engine,
                CREATE_TIME as created_at
            FROM information_schema.TABLES
            WHERE TABLE_SCHEMA = %s
            ORDER BY TABLE_NAME
        """, (DB_CONFIG['database'],))
        
        tables = cursor.fetchall()
        
        # è½¬æ¢datetimeä¸ºå­—ç¬¦ä¸²
        for table in tables:
            if table.get('created_at'):
                table['created_at'] = table['created_at'].isoformat()
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'data': tables,
            'count': len(tables)
        })
    
    except Exception as e:
        logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False, 
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500
    finally:
        if conn:
            conn.close()


@app.route('/api/table/<table_name>', methods=['GET'])
def get_table_data(table_name):
    """è·å–è¡¨æ•°æ®ï¼ˆåˆ†é¡µï¼‰"""
    conn = None
    try:
        page = int(request.args.get('page', 1))
        page_size = int(request.args.get('page_size', 20))
        offset = (page - 1) * page_size
        
        # éªŒè¯è¡¨åï¼ˆé˜²æ­¢SQLæ³¨å…¥ï¼‰
        valid_tables = [
            'actors', 'repos', 'organizations', 'events',
            'payload_push', 'payload_issue', 'payload_pull_request',
            'payload_star', 'payload_fork', 'payload_create', 'payload_delete',
            'payload_watch',
            'hot_repos', 'active_developers', 'event_stats_daily',
            'user_repo_relation', 'repo_stats_cache', 'actor_stats_cache'
        ]
        
        if table_name not in valid_tables:
            return jsonify({'success': False, 'error': f'æ— æ•ˆçš„è¡¨å: {table_name}'}), 400
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # è·å–æ€»è¡Œæ•°
        cursor.execute(f"SELECT COUNT(*) as total FROM `{table_name}`")
        total = cursor.fetchone()['total']
        
        # è·å–æ•°æ®
        cursor.execute(f"SELECT * FROM `{table_name}` LIMIT %s OFFSET %s", (page_size, offset))
        rows = cursor.fetchall()
        
        # è½¬æ¢datetimeä¸ºå­—ç¬¦ä¸²
        for row in rows:
            for key, value in list(row.items()):
                if isinstance(value, datetime):
                    row[key] = value.isoformat()
        
        # è·å–åˆ—ä¿¡æ¯
        cursor.execute(f"DESCRIBE `{table_name}`")
        columns = [
            {
                'field': col['Field'],
                'type': col['Type'],
                'key': col['Key'],
                'comment': col.get('Extra', '')
            }
            for col in cursor.fetchall()
        ]
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'data': {
                'rows': rows,
                'columns': columns,
                'pagination': {
                    'page': page,
                    'page_size': page_size,
                    'total': total,
                    'total_pages': (total + page_size - 1) // page_size
                }
            }
        })
    
    except Exception as e:
        logger.error(f"è·å–è¡¨æ•°æ®å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False, 
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500
    finally:
        if conn:
            conn.close()


@app.route('/api/query', methods=['POST'])
def execute_query():
    """æ‰§è¡Œè‡ªå®šä¹‰SQLæŸ¥è¯¢ï¼ˆåªè¯»ï¼‰"""
    conn = None
    try:
        data = request.get_json()
        sql = data.get('sql', '').strip()
        
        if not sql:
            return jsonify({'success': False, 'error': 'SQLä¸èƒ½ä¸ºç©º'}), 400
        
        # å®‰å…¨æ£€æŸ¥ï¼šåªå…è®¸SELECTè¯­å¥
        sql_upper = sql.upper()
        if not sql_upper.startswith('SELECT'):
            return jsonify({'success': False, 'error': 'åªå…è®¸æ‰§è¡ŒSELECTæŸ¥è¯¢'}), 400
        
        # ç¦æ­¢çš„å…³é”®å­—
        forbidden_keywords = ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 'TRUNCATE']
        for keyword in forbidden_keywords:
            if keyword in sql_upper:
                return jsonify({'success': False, 'error': f'ç¦æ­¢ä½¿ç”¨ {keyword} è¯­å¥'}), 400
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # é™åˆ¶è¿”å›è¡Œæ•°
        max_rows = 1000
        if 'LIMIT' not in sql_upper:
            sql = f"{sql} LIMIT {max_rows}"
        
        # æ‰§è¡ŒæŸ¥è¯¢
        start_time = datetime.now()
        cursor.execute(sql)
        rows = cursor.fetchall()
        execution_time = (datetime.now() - start_time).total_seconds()
        
        # è½¬æ¢datetime
        for row in rows:
            for key, value in list(row.items()):
                if isinstance(value, datetime):
                    row[key] = value.isoformat()
        
        # è·å–åˆ—å
        columns = [desc[0] for desc in cursor.description] if cursor.description else []
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'data': {
                'rows': rows,
                'columns': columns,
                'count': len(rows),
                'execution_time': execution_time
            }
        })
    
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False, 
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500
    finally:
        if conn:
            conn.close()


@app.route('/api/stats/overview', methods=['GET'])
def get_overview_stats():
    """è·å–æ€»ä½“ç»Ÿè®¡"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        stats = {}
        
        cursor.execute("SELECT COUNT(*) as total FROM events")
        stats['total_events'] = cursor.fetchone()['total']
        
        cursor.execute("SELECT COUNT(*) as total FROM actors")
        stats['total_actors'] = cursor.fetchone()['total']
        
        cursor.execute("SELECT COUNT(*) as total FROM repos")
        stats['total_repos'] = cursor.fetchone()['total']
        
        cursor.execute("SELECT COUNT(*) as total FROM organizations")
        stats['total_orgs'] = cursor.fetchone()['total']
        
        cursor.execute("SELECT MAX(created_at) as latest FROM events")
        result = cursor.fetchone()
        latest = result['latest'] if result else None
        stats['latest_event'] = latest.isoformat() if latest else None
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'data': stats
        })
    
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False, 
            'error': str(e)
        }), 500
    finally:
        if conn:
            conn.close()


@app.route('/api/stats/event_types', methods=['GET'])
def get_event_type_stats():
    """è·å–äº‹ä»¶ç±»å‹åˆ†å¸ƒ"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                event_type,
                COUNT(*) as count
            FROM events
            GROUP BY event_type
            ORDER BY count DESC
            LIMIT 20
        """)
        
        results = cursor.fetchall()
        cursor.close()
        
        return jsonify({
            'success': True,
            'data': results
        })
    
    except Exception as e:
        logger.error(f"è·å–äº‹ä»¶ç±»å‹ç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn:
            conn.close()


@app.route('/api/trending/repos', methods=['GET'])
def get_trending_repos():
    """è·å–çƒ­é—¨ä»“åº“ï¼ˆè‡ªåŠ¨é™çº§ï¼‰"""
    conn = None
    try:
        limit = int(request.args.get('limit', 10))
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # å…ˆå°è¯•ä»çƒ­é—¨è¡¨è·å–
        cursor.execute("SHOW TABLES LIKE 'hot_repos'")
        table_exists = cursor.fetchone()
        
        repos = []
        source = 'empty'
        
        if table_exists:
            cursor.execute("""
                SELECT 
                    repo_id,
                    repo_name,
                    score,
                    stars_7d,
                    forks_7d,
                    prs_7d,
                    rank_position
                FROM hot_repos
                ORDER BY rank_position
                LIMIT %s
            """, (limit,))
            repos = cursor.fetchall()
            source = 'cached'
        
        # å¦‚æœçƒ­é—¨è¡¨ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œä½¿ç”¨é™çº§æŸ¥è¯¢
        if not repos:
            logger.warning("hot_reposè¡¨ä¸ºç©ºï¼Œä½¿ç”¨é™çº§æŸ¥è¯¢")
            
            # æ£€æŸ¥ repos è¡¨çš„å®é™…åˆ—å
            cursor.execute("SHOW COLUMNS FROM repos")
            columns = [row['Field'] for row in cursor.fetchall()]
            logger.info(f"reposè¡¨åˆ—å: {columns}")
            
            # ä½¿ç”¨å®é™…çš„åˆ—åï¼ˆæ ¹æ®ä½ çš„è¡¨ç»“æ„è°ƒæ•´ï¼‰
            name_column = 'name' if 'name' in columns else 'full_name'
            stars_column = 'total_stars' if 'total_stars' in columns else 'stargazers_count'
            
            cursor.execute(f"""
                SELECT 
                    r.repo_id,
                    r.{name_column} as repo_name,
                    COALESCE(r.{stars_column}, 0) as score,
                    COUNT(CASE 
                        WHEN e.event_type = 'WatchEvent' 
                        AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) 
                        THEN 1 
                    END) as stars_7d,
                    COUNT(CASE 
                        WHEN e.event_type = 'ForkEvent' 
                        AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) 
                        THEN 1 
                    END) as forks_7d,
                    COUNT(CASE 
                        WHEN e.event_type = 'PullRequestEvent' 
                        AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) 
                        THEN 1 
                    END) as prs_7d,
                    ROW_NUMBER() OVER (ORDER BY r.{stars_column} DESC) as rank_position
                FROM repos r
                LEFT JOIN events e ON r.repo_id = e.repo_id 
                    AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                GROUP BY r.repo_id, r.{name_column}, r.{stars_column}
                ORDER BY score DESC
                LIMIT %s
            """, (limit,))
            repos = cursor.fetchall()
            source = 'realtime'
        
        cursor.close()
        
        logger.info(f"è¿”å› {len(repos)} ä¸ªçƒ­é—¨ä»“åº“ (æ¥æº: {source})")
        if repos and len(repos) > 0:
            logger.info(f"ç¬¬ä¸€æ¡æ•°æ®: {repos[0]}")
        
        return jsonify({
            'success': True,
            'data': repos,
            'source': source
        })
    
    except Exception as e:
        logger.error(f"è·å–çƒ­é—¨ä»“åº“å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn:
            conn.close()


@app.route('/api/trending/developers', methods=['GET'])
def get_trending_developers():
    """è·å–æ´»è·ƒå¼€å‘è€…ï¼ˆè‡ªåŠ¨é™çº§ï¼‰"""
    conn = None
    try:
        limit = int(request.args.get('limit', 10))
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # å…ˆå°è¯•ä»æ´»è·ƒè¡¨è·å–
        cursor.execute("SHOW TABLES LIKE 'active_developers'")
        table_exists = cursor.fetchone()
        
        developers = []
        source = 'empty'
        
        if table_exists:
            cursor.execute("""
                SELECT 
                    actor_id,
                    actor_login,
                    activity_score,
                    commits_7d,
                    prs_7d,
                    issues_7d,
                    rank_position
                FROM active_developers
                ORDER BY rank_position
                LIMIT %s
            """, (limit,))
            developers = cursor.fetchall()
            source = 'cached'
        
        # å¦‚æœæ´»è·ƒè¡¨ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œä½¿ç”¨é™çº§æŸ¥è¯¢
        if not developers:
            logger.warning("active_developersè¡¨ä¸ºç©ºï¼Œä½¿ç”¨é™çº§æŸ¥è¯¢")
            
            # æ£€æŸ¥ actors è¡¨çš„å®é™…åˆ—å
            cursor.execute("SHOW COLUMNS FROM actors")
            columns = [row['Field'] for row in cursor.fetchall()]
            logger.info(f"actorsè¡¨åˆ—å: {columns}")
            
            # ä½¿ç”¨å®é™…çš„åˆ—å
            login_column = 'login' if 'login' in columns else 'username'
            events_column = 'total_events' if 'total_events' in columns else 'public_events'
            
            cursor.execute(f"""
                SELECT 
                    a.actor_id,
                    a.{login_column} as actor_login,
                    COALESCE(a.{events_column}, 0) as activity_score,
                    COUNT(CASE 
                        WHEN e.event_type = 'PushEvent' 
                        AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) 
                        THEN 1 
                    END) as commits_7d,
                    COUNT(CASE 
                        WHEN e.event_type = 'PullRequestEvent' 
                        AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) 
                        THEN 1 
                    END) as prs_7d,
                    COUNT(CASE 
                        WHEN e.event_type = 'IssuesEvent' 
                        AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) 
                        THEN 1 
                    END) as issues_7d,
                    ROW_NUMBER() OVER (ORDER BY a.{events_column} DESC) as rank_position
                FROM actors a
                LEFT JOIN events e ON a.actor_id = e.actor_id 
                    AND e.created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                GROUP BY a.actor_id, a.{login_column}, a.{events_column}
                ORDER BY activity_score DESC
                LIMIT %s
            """, (limit,))
            developers = cursor.fetchall()
            source = 'realtime'
        
        cursor.close()
        
        logger.info(f"è¿”å› {len(developers)} ä¸ªæ´»è·ƒå¼€å‘è€… (æ¥æº: {source})")
        if developers and len(developers) > 0:
            logger.info(f"ç¬¬ä¸€æ¡æ•°æ®: {developers[0]}")
        
        return jsonify({
            'success': True,
            'data': developers,
            'source': source
        })
    
    except Exception as e:
        logger.error(f"è·å–æ´»è·ƒå¼€å‘è€…å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn:
            conn.close()


# é”™è¯¯å¤„ç†
@app.errorhandler(404)
def not_found(e):
    return jsonify({'success': False, 'error': 'é¡µé¢æœªæ‰¾åˆ°'}), 404


@app.errorhandler(500)
def internal_error(e):
    logger.error(f"å†…éƒ¨é”™è¯¯: {e}")
    logger.error(traceback.format_exc())
    return jsonify({
        'success': False, 
        'error': 'å†…éƒ¨æœåŠ¡å™¨é”™è¯¯',
        'detail': str(e),
        'traceback': traceback.format_exc()
    }), 500


if __name__ == '__main__':
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_vars = ['DB_HOST', 'DB_NAME', 'WEB_DB_USER', 'WEB_DB_PASSWORD']
    missing = [v for v in required_vars if not os.getenv(v)]
    
    if missing:
        logger.error(f"ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing)}")
        logger.error("è¯·æ£€æŸ¥ .env æ–‡ä»¶")
        exit(1)
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    try:
        test_conn = get_db_connection()
        test_conn.close()
        logger.info("âœ“ æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
    except Exception as e:
        logger.error("âœ— æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥")
        logger.error(str(e))
        exit(1)
    
    logger.info("=" * 60)
    logger.info("ğŸš€ å¯åŠ¨ GHPulse Web åº”ç”¨")
    logger.info(f"ğŸ“ è®¿é—®åœ°å€: http://localhost:5000")
    logger.info(f"ğŸ“ APIæ–‡æ¡£: http://localhost:5000/api/health")
    logger.info("=" * 60)
    
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=True
    )